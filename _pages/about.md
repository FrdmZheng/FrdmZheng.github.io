---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

åˆ˜æˆé¾™ï¼Œç”·ï¼Œå‰¯æ•™æˆï¼ŒåŒæµå¤§å­¦äº¤é€šç§‘å­¦ä¸æŠ€æœ¯ç ”ç©¶é™¢å‰¯é™¢é•¿ã€‚å…¥é€‰ä¸Šæµ·å¸‚å¯æ˜æ˜Ÿç§‘æŠ€äººæ‰ã€ä¸­å›½å…¬è·¯å­¦ä¼šé’å¹´æ‰˜ä¸¾äººæ‰ã€ä¸Šæµ·35äººé’å¹´ç§‘æŠ€å¼•é¢†è®¡åˆ’ç­‰ã€‚æ‹…ä»»è”åˆå›½äºšå¤ªç»æµç¤¾ä¼šç»„ç»‡ï¼ˆESCAPï¼‰å’¨è¯¢ä¸“å®¶ã€ä¸–ç•Œäº¤é€šè¿è¾“å¤§ä¼š(WTC)æ•°å­—åŒ–è¿ç»´æŠ€æœ¯å§”å‘˜ä¼šç§˜æœ¯å§”å‘˜ ã€ä¸Šæµ·å¸‚å…¬è·¯å­¦ä¼šå…»æŠ¤ä¸ç®¡ç†ä¸“å§”ä¼šå§”å‘˜ç­‰ã€‚ä¸»è¦ä»äº‹é“è·¯å·¥ç¨‹ä¸ä¿¡æ¯å·¥ç¨‹äº¤å‰æ–¹å‘ç ”ç©¶ï¼Œå»ºç«‹äº†è·¯é¢è¡Œé©¶è´¨é‡è½»é‡åŒ–æ£€æµ‹æŠ€æœ¯ä¸é«˜é¢‘å¤šç»´çš„é“è·¯æœå½¹çŠ¶æ€ç²¾ç»†åŒ–è¯„ä»·æ–¹æ³•ï¼Œæå‡ºäº†åŸºäºç»†ç²’åº¦æ—¶ç©ºæ•°æ®çš„é“è·¯åŸºç¡€è®¾æ–½ç®¡å…»ä¼˜åŒ–ç†è®ºï¼Œæ¨åŠ¨äº†ä»¥â€œè½»é‡åŒ–å¿«é€Ÿå·¡æ£€â€ä¸ºç‰¹å¾çš„é“è·¯è®¾æ–½æ•°å­—åŒ–ç®¡å…»æŠ€æœ¯è½¬å‹ã€‚ç ”ç©¶æˆæœåœ¨AICã€Transport Res. Cã€IEEE Trans. ITSã€ä¸­å›½å…¬è·¯å­¦æŠ¥ç­‰é«˜æ°´å¹³æœŸåˆŠå‘è¡¨ç ”ç©¶è®ºæ–‡50ä½™ç¯‡ï¼Œå¤šé¡¹ç ”ç©¶æˆæœç›¸ç»§è¢«é´é€‰ä¸ºIEEE ITSMå°é¢è®ºæ–‡ã€ESIé«˜è¢«å¼•è®ºæ–‡/çƒ­ç‚¹è®ºæ–‡ã€ä¸­å›½å…¬è·¯å­¦æŠ¥å¹´åº¦ä¼˜ç§€è®ºæ–‡ã€äº¤é€šéƒ¨é‡å¤§ç§‘æŠ€æˆæœ(è®ºæ–‡ç±»)ã€COTA Best Presentation Awardç­‰ã€‚ç›¸å…³æˆæœè·æˆæƒä¸­å›½ã€ç¾å›½ã€è‹±å›½ã€å›½é™…ä¸“åˆ©30ä½™é¡¹ï¼Œè£è·ä¸­å›½ä¸“åˆ©ä¼˜ç§€å¥–ã€ä¸Šæµ·å¸‚ç™¾å¼ºé«˜ä»·å€¼ä¸“åˆ©ç­‰ï¼Œå¹¶å®ç°äº†äº§ä¸šåŒ–åº”ç”¨ï¼Œè¦†ç›–å…¨å›½äºŒåä½™çœä»½åº”ç”¨é‡Œç¨‹è¶…40ä¸‡å…¬é‡Œã€‚ä½œä¸ºä¸»è¦å®Œæˆäººè·å¾—ä¸Šæµ·å¸‚ç§‘æŠ€è¿›æ­¥ä¸€ç­‰å¥–ã€ä¸­å›½å…¬è·¯å­¦ä¼šç§‘å­¦æŠ€æœ¯ç‰¹ç­‰å¥–/ä¸€ç­‰å¥–ã€ä¸­å›½äº¤é€šè¿è¾“åä¼šç§‘å­¦è¿›æ­¥ä¸€ç­‰å¥–ã€ä¸­å›½å‘æ˜åä¼šå‘æ˜åˆ›æ–°ä¸€ç­‰å¥–ç­‰9é¡¹ã€‚

# ğŸ“– Educations
- *2010.09 - 2014.06*, [åŒæµå¤§å­¦](https://www.tongji.edu.cn/), äº¤é€šå·¥ç¨‹, å­¦å£«.
- *2017.09 - 2018.09*, [åç››é¡¿å¤§å­¦](https://www.washington.edu/), åœŸæœ¨ç¯å¢ƒå·¥ç¨‹, è”åˆåŸ¹å…»åšå£«.
- *2014.09 - 2019.06*, [åŒæµå¤§å­¦](https://www.tongji.edu.cn/), äº¤é€šè¿è¾“å·¥ç¨‹, åšå£«.

# ğŸ’» Professional Experiences
- *2019.12 - 2022.12*, [åŒæµå¤§å­¦](https://www.tongji.edu.cn/), äº¤é€šè¿è¾“å·¥ç¨‹å­¦é™¢, åšå£«å.
- *2021.05 - è‡³ä»Š*,    [åŒæµå¤§å­¦](https://www.tongji.edu.cn/), äº¤é€šç§‘å­¦ä¸æŠ€æœ¯ç ”ç©¶é™¢, å‰¯æ•™æˆ.
- *2023.02 - è‡³ä»Š*   , [åŒæµå¤§å­¦](https://www.tongji.edu.cn/), äº¤é€šè¿è¾“å·¥ç¨‹å­¦é™¢, å‰¯æ•™æˆ.
- *2024.01 - è‡³ä»Š* ,   [åŒæµå¤§å­¦](https://www.tongji.edu.cn/), äº¤é€šè¿è¾“å·¥ç¨‹å­¦é™¢, å‰¯é™¢é•¿.

# ğŸ” Projects
- ğŸ”¥`Newï¼`*2023*å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’, æ™ºèƒ½ç½‘è”é“è·¯äº¤é€šç³»ç»Ÿçš„èƒ½æºè‡ªæ´½æŠ€æœ¯, å­è¯¾é¢˜ä¸»æŒ
- ğŸ”¥`Newï¼`*2022*å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’, å¼¹æ€§äº¤é€šç³»ç»Ÿä¿¡æ¯ç‰©ç†ä½“ç³»æ„å»º, å­è¯¾é¢˜ä¸»æŒ
- *2019*å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’, æ¸¯ç æ¾³å¤§æ¡¥æ™ºèƒ½åŒ–è¿ç»´æŠ€æœ¯é›†æˆåº”ç”¨, é¡¹ç›®éª¨å¹²
- ğŸ”¥`Newï¼`*2022*å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘, ä¼—ç­¹æ•°æ®é©±åŠ¨çš„åŸå¸‚è·¯ç½‘å¹³æ•´åº¦æ„ŸçŸ¥æ–¹æ³•ç ”ç©¶, ä¸»æŒ
- ğŸ”¥`Newï¼`*2023*ä¸Šæµ·å¸‚ç§‘æŠ€åˆ›æ–°è¡ŒåŠ¨è®¡åˆ’, é“è·¯åŸºç¡€è®¾æ–½å¤šç»´ä½“å¾çš„æ•°å­—åŒ–æ„ŸçŸ¥ä¸è¯„ä»·æ–¹æ³•ç ”ç©¶, ä¸»æŒ
- *2021*ä¸Šæµ·å¸‚ç§‘æŠ€åˆ›æ–°è¡ŒåŠ¨è®¡åˆ’, å¤æ‚åœ°ä¸‹é“è·¯éŸ§æ€§è¿è¡Œä¸æ™ºæ…§é˜²ç¾å…³é”®æŠ€æœ¯ç ”ç©¶ä¸ç¤ºèŒƒ, å­è¯¾é¢˜ä¸»æŒ
- *2021*æµ™æ±Ÿçœé“æ¡¥æ£€æµ‹ä¸å…»æŠ¤æŠ€æœ¯ç ”ç©¶é‡ç‚¹å®éªŒå®¤åŸºé‡‘, åŸºäºæ—¶ç©ºæ•°æ®åŒ¹é…çš„è·¯é¢æœå½¹çŠ¶æ€å¤§æ•°æ®è¯„ä»·æŠ€æœ¯, ä¸»æŒ

# ğŸ“ Publications 
ğŸ“ƒ Papers
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">2023</div><img src='images/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Cross-scene pavement distress detection by a novel transfer learning framework](https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12674)

Yishun Li, Pengyu Che, **Chenglong Liu**, Difei Wu, Yuchuan Du

We presents a framework for the cross-scenedeployment of distress detection models based on TL anda GAN. This framework dramatically assists deep learn-ing distress detection models deployed in new scenarioswithout degrading prediction performance. With the sameaccuracy, this method reduced the need for training databy at least 25%. Using the same amount of training data,this method also improved the mAP by about 26.55%.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">2023</div><img src='images/2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Large-scale pavement roughness measurements with vehicle crowdsourced data using semi-supervised learning](https://www.sciencedirect.com/science/article/pii/S0968090X21000784)

**Chenglong Liu**, Difei Wu, Yishun Li, Yuchuan Du

We proposed an SSL model to rapidly evaluate large-scale pavement roughness based on crowdsourced data of multiple vehicles. The relationship between pavement roughness and in-car vibrations was mathematically derived using a PSD analysis and an LTI system. Based on the multi-vehicle vibration data, a self-training algorithm was devised that used both labeled and unlabeled data to comprehensively evaluate the IRIs. The confidences of the vehicular parameters and the IRI estimations were considered to ensure that we obtained the most reliable results in each iteration. A full-car simulation environment with eight degrees-of-freedom was constructed to verify the effectiveness of the proposed model. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">2022</div><img src='images/3.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Comfortable and energy-efficient speed control of autonomous vehicles on rough pavements using deep reinforcement learning](https://www.sciencedirect.com/science/article/pii/S0968090X21004757)

Yuchuan Du, Jing Chen, Cong Zhao, **Chenglong Liu**, Feixiong Liao, Ching-Yao Chan

We proposed a speed control framework on rough pavement based on the crowdsourced data. We suggest the concept of the maximum comfortable speed to represent the vertical ride comfort of the oncoming road in this framework. A speed control model based on deep reinforcement learning was designed, trained, and tested with the real-world rough pavements in Shanghai, China. To balance driving efficiency, ride comfort, and energy efficiency requirements, the reward function is designed with the consideration of speed, vertical vibration, longitudinal jerk, longitudinal acceleration, and vehicle-specific power.
</div>
</div>

- ``International Journal of Pavement Engineering 2024`` Fast calibration for vibration-based pavement roughness measurement based on model updating of vehicle dynamics, Difei Wu, **Chenglong Liu**, Bohao Qin, Sheng Zhong, Xiaoming Zhang, Yuchuan Du
- ``Automation in Construction 2024`` Advances in automatic identification of road subsurface distress using ground penetrating radar: State of the art and future trends, **Chenglong Liu**, Yuchuan Du, Guanghua Yue, Yishun Li, Difei Wu, Feng Li
- ``IEEE transactions on intelligent transportation systems 2023`` Fine-Grained Pavement Performance Prediction Based on Causal-Temporal Graph Convolution Networks, Wenyuan Cai, Andi Song, Yuchuan Du, **Chenglong Liu**, Difei Wu, Feng Li
- ``Applied Sciences 2023`` Differences evaluation of pavement roughness distribution based on light detection and ranging data, Qian Gao,Lei Fan,Siyu Wei,Yishun Li,Yuchuan Du, **Chenglong Liu**
- ``äº¤é€šè¿è¾“ç ”ç©¶ 2023`` åŸºäºLiDARä¸‰ç»´æ•°æ®çš„è·¯é¢å¹³æ•´åº¦æ¨ªå‘åˆ†å¸ƒå·®å¼‚ç‰¹æ€§è¯„ä¼°æ–¹æ³•, **åˆ˜æˆé¾™**, é­æ–¯ç‘€, é«˜å€©, å´è»é, æ›¹é™, æœè±«å·
- ``Automation in Construction 2023`` Modeling automatic pavement crack object detection and pixel-level segmentation, Yuchuan Du, Shan Zhong, Hongyuan Fang, Niannian Wang, **Chenglong Liu**, Difei Wu, Yan Sun, Mang Xiang
- ``IJTST 2023`` Enabling Edge Computing Ability in View-Independent Vehicle Model Recognition, **Chenglong Liu**, Ziyuan Pu, Yishun Li, Ying Jiang, Yinhai Wang, Yuchuan Du
- ``ä¸­å›½å…¬è·¯å­¦æŠ¥ 2023`` æ¢åœ°é›·è¾¾å¤šç‰¹å¾èåˆçš„åŸå¸‚ç©ºæ´è‡ªåŠ¨è¯†åˆ«æ–¹æ³•ç ”ç©¶, æœè±«å·, å²³å…‰å, **åˆ˜æˆé¾™**, æå³°, è”¡æ–‡æ‰

# ğŸ“š Patents
- ä¸€ç§åŸºäºå…³è”è§„åˆ™åˆ†æçš„é“è·¯æ·±å±‚ç—…å®³é¢„è­¦æ–¹æ³•	ZL202110215728.6
- ä¸€ç§æŒ¯åŠ¨å¼è·¯é¢å¹³æ•´åº¦æµ‹è¯•è½¦çš„æ ‡å®šæ–¹æ³•	ZL202110661532.X
- ä¸€ç§è·¯é¢æŸä¼¤å¿«é€Ÿæ£€æµ‹å’Œè‡ªç„¶æ•°æ®é›†æ„å»ºæ–¹æ³•	ZL202110073970.4
- ä¸€ç§åŸºäºå¤šæºç‰¹å¾èåˆçš„è·¯é¢æŸä¼¤æ•°æ®æ—¶ç©ºåˆ†ææ–¹æ³•	ZL202110074435.0
- ä¸€ç§åŸºäºæ‘©æ“¦æ¥è§¦é¢é¢„ä¼°çš„è·¯é¢æŠ—æ»‘æ€§èƒ½è¯„ä»·æ–¹æ³•	ZL202110121825.X
- ä¸€ç§è€ƒè™‘ç¢³æ’æ”¾çš„è·¯ç½‘çº§å…¨ç”Ÿå‘½å…»æŠ¤ä¼˜åŒ–æ–¹æ³•	ZL202210139768.1
- åŸºäºå¤šè½¦ä¼—ç­¹æŒ¯åŠ¨æ•°æ®çš„è·¯ç½‘çº§å¹³æ•´åº¦æ£€æµ‹æ–¹æ³•	ZL202210144895.0
- A method for leakage detection of underground corridor based on static infrared thermal image processing(GB2569751)
- Comfort-based self-driving planning method(US 11,447,150 B2)
- Method of controlling automated driving speed based on comfort level(WO/2018/122586)

# ğŸ† Honors and Awards
ğŸ… Honors
- ğŸ”¥`Newï¼`*2023* ä¸­å›½äº¤é€šåä¼šç§‘æŠ€è¿›æ­¥ä¸€ç­‰å¥– é«˜é€Ÿå…¬è·¯æ•°æ™ºå…»æŠ¤ä¸å†³ç­–å¹³å°å»ºè®¾å…³é”®æŠ€æœ¯ç ”ç©¶åŠå¼€å‘
- ğŸ”¥`Newï¼`*2023* ä¸­å›½äº¤é€šåä¼šç§‘æŠ€è¿›æ­¥äºŒç­‰å¥– åŒ—éƒ¨æ¹¾æ¹¿çƒ­åœ°åŒºæ²¥é’è·¯é¢ç—…å®³æ™ºèƒ½è¯†åˆ«ä¸åŠŸèƒ½æå‡å…³é”®æŠ€æœ¯åŠåº”ç”¨
- ğŸ”¥`Newï¼`*2023* ã€Šä¸­å›½å…¬è·¯å­¦æŠ¥ã€‹å¹´åº¦ä¼˜ç§€è®ºæ–‡äºŒç­‰å¥–
- ğŸ”¥`Newï¼`*2023* è”åˆå›½æŠ¥å‘Šè¯æ˜ Supporting the policies on green and resilient transport infrastructure along the Asian Highway Network
- ğŸ”¥`Newï¼`*2023* é«˜PCSIã€é«˜è¢«å¼•ã€é«˜ä¸‹è½½è®ºæ–‡ æ–°ä¸€ä»£æ™ºæ…§é«˜é€Ÿå…¬è·¯ç³»ç»Ÿæ¶æ„è®¾è®¡
- *2023* åŒæµå¤§å­¦ç ”ç©¶ç”Ÿå…ˆç”Ÿç²¾å“è¯¾ç¨‹ äº¤é€šæ•°æ®åˆ†æä¸åº”ç”¨
- *2023* ä¸Šæµ·äº§å­¦ç ”åˆä½œä¼˜ç§€é¡¹ç›®å¥–ä¸‰ç­‰å¥– é“è·¯å¤šç»´é«˜é¢‘æ£€æµ‹è£…å¤‡å’Œæ™ºèƒ½å…»æŠ¤æŠ€æœ¯åŠåº”ç”¨
- *2023* ä¸­å›½å…¬è·¯å­¦ä¼šç§‘å­¦æŠ€æœ¯å¥–ç‰¹ç­‰å¥– é•¿è·ç¦»é«˜é€Ÿå…¬è·¯æ™ºèƒ½å»ºé€ ä¸è¿ç»´å…³é”®æŠ€æœ¯ç ”ç©¶åŠåº”ç”¨
- *2023* ä¸Šæµ·å¸‚å…¬è·¯å­¦ä¼šç§‘æŠ€è¿›æ­¥å¥–äºŒç­‰å¥–

ğŸ“š Foundations
- ğŸ”¥`Newï¼`*2023* ä¸Šæµ·å¸‚ç§‘æŠ€åˆ›æ–°è¡ŒåŠ¨è®¡åˆ’-é“è·¯åŸºç¡€è®¾æ–½å¤šç»´ä½“å¾çš„æ•°å­—åŒ–æ„ŸçŸ¥ä¸è¯„ä»·æ–¹æ³•ç ”ç©¶
- ğŸ”¥`Newï¼`*2023* å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’-æ™ºèƒ½ç½‘è”é“è·¯äº¤é€šç³»ç»Ÿçš„èƒ½æºè‡ªæ´½æŠ€æœ¯
- ğŸ”¥`Newï¼`*2023* åŒæµå¤§å­¦äº¤å‰å­¦ç§‘é¡¹ç›®-çŸ¥è¯†-æ•°æ®ååŒé©±åŠ¨çš„ç²¾ç»†åŒ–é“è·¯å…»æŠ¤ç­–ç•¥ç”Ÿæˆæ–¹æ³•
- *2021* å›½å®¶è‡ªç„¶åŸºé‡‘é’å¹´é¡¹ç›®-ä¼—ç­¹æ•°æ®é©±åŠ¨çš„åŸå¸‚è·¯ç½‘å¹³æ•´åº¦æ„ŸçŸ¥æ–¹æ³•ç ”ç©¶


